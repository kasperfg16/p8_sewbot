gradient\_steps:1\\
batch\_size:50\\
discount\_factor:0.99\\
polyak:0.005\\
actor\_learning\_rate:0.001\\
critic\_learning\_rate:0.001\\
learning\_rate\_scheduler:None\\
learning\_rate\_scheduler\_kwargs:\\
state\_preprocessor:None\\
state\_preprocessor\_kwargs:\\
random\_timesteps:0\\
learning\_starts:50\\
grad\_norm\_clip:0\\
exploration:\\
{ \phantom - } noise:skrl.resources.noises.torch.gaussian.GaussianNoise\\
{ \phantom - } initial\_scale:1.0\\
{ \phantom - } final\_scale:0\\
{ \phantom - } timesteps:None\\
rewards\_shaper:None\\
experiment:\\
{ \phantom - } directory:runs_for_report\\
{ \phantom - } experiment\_name:DDPG_env_iteration_2_config_1\\
{ \phantom - } write\_interval:5\\
{ \phantom - } checkpoint\_interval:500\\
{ \phantom - } store\_separately:False\\
{ \phantom - } wandb:False\\
{ \phantom - } wandb\_kwargs:\\

description:

coverage reward increased from 50 to 100
done reward increased from 100 to 1000
batch and learning starts increased from 10 to 50
num env: 10